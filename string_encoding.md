# 字符串编码

请你用一句话说明你是个程序员，并标明你用的是何种语言。那我肯定会说`unicodeDecodeError`,
这个错误相信使用`Python`,尤其是`Python2`的人深有感触。

##### 一些概念

我们知道计算机是不能直接识别字符串的，只能识别0/1两个数字，
所有的东西在计算机内部都是一串有0/1组成数字。
那要计算机显示或处理所有的字符，就必须把所有的字符与数字映射起来。

###### 字符
`字符`是各种文字符号的总称，包括各国文字、标点符号、图形符号、数字等。
###### 字符集
`字符集`是一个系统支持的所有抽象的字符的集合。定义了字符与数字之间的映射关系。一个字符对应的数字，成为`字符码`(code point, 代码点)。
常见的字符集有`ASCII`字符集、`Unicode`字符集、`GB2312`等。
在`ASCII`中规定了字符`A`对应的数字是65，即字符`A`的`字符码`为65。
汉字’中‘在`Unicode`中对应的数字为`Ox4e2d`，即十进制的`20013`。
`字符集`定义了`字符`与`字符码`之间的映射关系，但并没有规定这些映射关系要如何实现。
###### 字符编码
`字符编码`则定义了`字符集`的具体实现。`ASCII`既是一个字符集，也是一种编码。
在`ASCII`编码中字符`A`的字符码为65，在计算机中的实现也是65。
我们可以说`ASCII`既是一个`字符集`，也是一种`字符编码`方案。使用`Python`的`ord()`方法，可以看到`A`在内存中就是65。
```
>>> a = 'A'
>>> ord(a)
65
```
`Unicode`仅仅规定了`字符`与`字符码`之间的对应关系，并没有规定这些`字符`在计算机中的实现，
只是一个`字符集`，并不是一种编码方案。
在`Python`中执行以下代码可以看到，`Unicode`字符u`中`，在内存是`u'\u4e2d'`，只有两个字节，即u`中`的`code point`。但我用`UTF-8`编码之后，
`中`这个字在内存中就变成了`'\xe4\xb8\xad'`,成为了3个字节。在这里`UTF-8`是对`Unicode`字符集的编码。详细内容后文会讲到。
```
>>> a = u'中'
>>> a
u'\u4e2d'
>>> b = a.encode("utf8")
>>> b
'\xe4\xb8\xad'
```

##### 字符编码的历史

计算机是在美国发明的，英语26个英文字母，加上一些标点符号和数字，空格等，不超个128个，因此他们用7bit来映射这些字符，还有剩余的位就是放了一些控制字符。这就是我们最常见的[`ASCII`（American Standard Code for Information Interchange）](http://tool.oschina.net/commons?type=4)表。在计算机中一个字节（Byte）是8位，因此`ASCII`表的最高位是0。
后来发现128个字符也不够用了，于是就把`ASCII`码的最高位也用上了，于是就产生了扩展`ASCII`码表。

随着计算机进入欧洲，欧洲不同语言中会有不同的重音字母，虽然标准的`ASCII`不能满足需求，但稍作修改就能满足本国语言的需求。因此国际标准号组织在`ASCII`的基础上进行了扩展，形成了ISO-8859标准。但欧洲国家多呀，语言环境也复杂，一套标准并不能适用所有国家。所以产生了很多子标准。如针对西欧语言的[ISO/IEC 8859-1 (Latin-1) ](https://zh.wikipedia.org/wiki/ISO/IEC_8859)，针对希腊语的  [ISO/IEC 8859-7 (Greek)](https://zh.wikipedia.org/wiki/ISO/IEC_8859)等，总共15个子标准。


在欧洲，虽然标准很多，但用一个字节（Byte）基本能够覆盖一个字符集。但计算机进入亚洲之后傻眼了。一个字节，8位，仅仅编码256个字符，不说别的，就汉字就何止千千万，这国际标准也不能适用了。于是各个国家和地区制定了自己的编码标准，如适用于简体中文的`GB2312`， `GBK`， `GB18030`，适用于繁体中文的`BIG5`，日本的`Shift JIS`的。这些标准用两到三个字节编码一个字符。


##### Unicode
有了这么多编码之后，字符在计算机的存储没问题了。但同一个数字在不同的编码内代表不同的字符，这就造成了乱码的问题。我一个中国人，我写汉字，使用`GBK`编码，有天我用中文写了一封邮件，“中国欢迎你” 发到了美国，他们用`ASCII`码表解码，有可能看到的是这样“�й���ӭ��” 。

为了解决这个乱象，Unicode组织和国际标准组织（ISO）联合起来制定了Universial Charscter Set（UCS），又称万国码，就是要把世界上所有的字符都用统一的形式表示。我们可以认为`Unicode`和`UCS`是同义词。一开始`Unicode`用两个字节表示一个字符，例如字母`A`用`0x0041`表示，汉字`中`用`0x4e2d`表示。`Unicode`并不是颁布完就不维护了，其中收录的字符还在不断的增加中，到2001年，Unicode 3.2（ISO/IEC 10646-1:2000ISO/IEC 10646-2:2001）发布是，就已经包含了94205个字符，两个字节最多包含65536个字符，已经无法编码这些字符了。那怎么办呢？`Unicode`采用基准面（Plan）的方式解决这个问题。实际上`0x0000`-`0xFFFF`之间的编码区段并不是每一个位置都对应了字符，`0xE000`-`0xF8FF`是保留区域，可以留作它用。`0xFFF0`-`0xFFFF`则是用来构造辅助平面的。之前的16位字符构成基本多文种平面（Basic Multiple Language Plane， BMP）或称第0平面，Plan0，16位中的保留区间和增加的位数构成了16个辅助平面，辅助平面采用4个字节编码字符，大约可以编码一百多万字符。

在这里还要重申一遍，`Unicode`只是定义了字符与数字之间的映射关系，但并未规定这些字符在计算机中如何传输和存储。例如汉字`中`的`Unicode`码是`0x4e2d`，我可以用两个字节来存储，也可所以用四个字节来存储。具体的实现方式为是有Unicode转换格式（Unicode Transformation Format,UTF)规定的。


##### UTF

UTF规定了`Unicode`在计算机中的实现方式。

###### UTF-16
`UTF-16`是`Unicode`字符集的一种实现方式，其编码元为2个字节，即16位，这也是`UTF-16`名称的来源。`UTF-16`是一种变长编码。基准多文种平面内（BMP）的字符码位范围为`0x0000-0xFFFF`使用两个字节表示，辅助平面内的字符则处理成两个16位的字节对，成为代理对（surroagte pair）。

- `Unicode`规定`0xD800-0xDFFF`的区间不对应任何字符。
- `0x0000-0xD7FF`和`0xE000-0xFFFF`之间的字符使用两个字节，即一个码元。
- `0x10000-0x10FFFF`之间的字符使用代理对表示。
 + + 码位减去`0x10000`，得到20位的一个数字，范围在`0x00000-0xFFFFF`。
- + 高位的10比特（范围`0x0000-0x03FF`）+ 数字`0xD800`，得到的范围为`0xD800-0xDC00` ，被成为高位代理，也叫前导代理。
- + 低位的10比特（范围也是`0x0000-0x03FF`）+ 数字`0xDC00`，得到的范围为`0xDC00-0xDFFF`，被成为低位代理，也被成为后尾代理。
- 
这样的一对代码对使用BMP平面中2048个码位编码了1024×1024个字符。而且前导代理，后尾代理和正常的字符编码的范围不对，遇到一个码元，就能判断正确判断这个码元代表什么。

`UTF-16`用两个字节作为一个码元，因此不能和`ASCII`兼容，而且造成了一定的空间浪费。除此之外，`UTF-16`要在时间传输中使用就要考虑字节需的问题。如`中`的`Unicode`码为`0x4e2d`,如果高位在前就是`4e 2d`（大端），如果低位在前就是`2d 4e`，而`Unicode`中`0x2d4e`表示字符`ⵎ`。如果没有约定好字节序，到收到`0x2d4e`到底是汉字`中`呢还是`ⵎ`呢？`Unicode`规范中推荐的标记字节顺序的方法是`BOM`（Byte Order Marker）。`BOM`是一个零宽不间断字符，表明字节序。`FFFF`表明字节序为大端，`FEFF`表明字节序为小端。这样接收者收到一串字符后就能很好的解码了。

##### UTF-8
`UTF-16`编码设计的挺巧妙的，但不能兼容`ASCII`码。在英文国家已经有很多资料使用`ASCII`码，转成`UTF-16`，每个字符占用两个字节，也是一种对空间的浪费。`Unicode`的另一种实现，`UTF-8`很好的兼容了`ASCII`码。


UTF-8（8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码，也是一种前缀码。它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节仍与ASCII兼容，这使得原来处理ASCII字符的软件无须或只须做少部分修改，即可继续使用。

UTF-8使用一至六个字节为每个字符编码（尽管如此，2003年11月UTF-8被RFC 3629重新规范，只能使用原来Unicode定义的区域，U+0000到U+10FFFF，也就是说最多四个字节）：
  1. 128个US-ASCII字符只需一个字节编码（Unicode范围由U+0000至U+007F）。
  2. 带有附加符号的拉丁文、希腊文、西里尔字母、亚美尼亚语、希伯来文、阿拉伯文、叙利亚文及它拿字母则需要两个字节编码（Unicode范围由U+0080至U+07FF）。
  3. 其他基本多文种平面（BMP）中的字符（这包含了大部分常用字，如大部分的汉字）使用三个字节编码（Unicode范围由U+0800至U+FFFF）。
  4. 其他极少使用的Unicode 辅助平面的字符使用四至六字节编码（Unicode范围由U+10000至U+1FFFFF使用四字节，Unicode范围由U+200000至U+3FFFFFF使用五字节，Unicode范围由U+4000000至U+7FFFFFFF使用六字节）。
  


码点的位数  |   码点起值 |   码点终值 |  字节序列 | Byte1 | Byte2 | Byte3 | Byte4 | Byte5 | Byte6
----| ---- | ---- | ---- | ------ | -----| ----- | ----- | ----- | -----  
7 | U+0000 | U+007F | 1 | 0xxxxxxx | | | 
11 | U+0080 | U+07FF | 2 | 110xxxxx | 10xxxxxx
16 | U+0800 | U+FFFF | 3 | 1110xxxx | 10xxxx | 10xxxx
21 | U+10000 | U+1FFFFF | 4 | 11110xxx | 10xxxxxx | 10xxxxxx | 10xxxxxx | | 


  - 在ASCII码的范围，用一个字节表示，超出ASCII码的范围就用字节表示，这就形成了我们上面看到的UTF-8的表示方法，这様的好处是当UNICODE文件中只有ASCII码时，存储的文件都为一个字节，所以就是普通的ASCII文件无异，读取的时候也是如此，所以能与以前的ASCII文件兼容。
  - 大于ASCII码的，就会由上面的第一字节的前几位表示该unicode字符的长度，比如110xxxxx前三位的二进制表示告诉我们这是个2BYTE的UNICODE字符；1110xxxx是个三位的UNICODE字符，依此类推；xxx的位置由字符编码数的二进制表示的位填入。越靠右的x具有越少的特殊意义。只用最短的那个足够表达一个字符编码数的多字节串。注意在多字节串中，第一个字节的开头"1"的数目就是整个串中字节的数目。
  

 
UTF-8的设计有以下的多字符组序列的特质：
  - 单字节字符的最高有效比特永远为0。
  - 多字节序列中的首个字符组的几个最高有效比特决定了序列的长度。最高有效位为110的是2字节序列，而1110的是三字节序列，如此类推。
  - 多字节序列中其余的字节中的首两个最高有效比特为10。
  
`UTF-8`是一种自解释的编码方式。根据字节的首位就可以判断该字节承担的功能。因此，如果传输的过程中某个字节发生丢失，只会影响一个字符，不会影响其他字符，而`UTF-16`则会导致之后的字符全部错乱。`UTF-8`也不需要`BOM`来指定字节流的顺序。`Unicode`标准尽管允许使用`BOM`，但很多`Unix`系统是不支持`BOM`的。我曾经有同时在`Windows`上使用文本编辑器编辑文件之后保存为`UTF-8 BOM`格式，结果提交`SVN`的时候提交不上去。就是因为文件开头多了`FFFF`的`BOM`，把`FFFF`删掉之后再提交就正常了。

 在`JAVA`中，`Char`类型占两个字节，采用`UTF-16`的方式编码。严格的说，一个字符在`JAVA`中并不是占两个字节，而是`BMP`平面内的字符占两个字节，其他辅助平面的字符，采用代理对的形式表示，要占到四个字节。